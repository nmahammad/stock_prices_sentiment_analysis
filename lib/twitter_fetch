import os
import requests
import pandas as pd
from datetime import datetime, timedelta

# API credentials
API_KEY = 'CI5Ekn6MBnN8s2q7VLFushZXx'
API_SECRET_KEY = '2lRITnWOAFOV3qhksjAcxbI3iCGxC7rE1OTtAPTiVsuWtdkEk8'
ACCESS_TOKEN = '1646245338045349888-AnjUoA8yoQ5iThY57LZW0mrsVufQ7P'
ACCESS_TOKEN_SECRET = 'do5rfXGPT5OaMJcoZwDVcfbTQRlqZPDgnq64vlIw8c0lO'
BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAJEioAEAAAAAfdcUcfrG9UU6i5C8cyunJjvtz44%3DDamiep88WsI58HONgQzU3BQ9asUdvwhtsKBruWdY5QFn7ZtWcc'

# Twitter API endpoint
base_url = "https://api.twitter.com/2/tweets/search/recent"

# Query parameters
params = {
    'query': 'metaverse',
    "tweet.fields": "created_at",
    "max_results": 10
}

# Create a session object for making requests
session = requests.Session()
session.headers.update({"Authorization": f"Bearer {BEARER_TOKEN}"})

# Function to retrieve tweets using pagination
def retrieve_tweets():
    url = base_url
    tweets_per_hour = 10  # Number of tweets to retrieve per hour
    current_datetime = datetime(2023, 6, 6, 0, 0)  # Starting datetime

    while current_datetime < datetime(2023, 6, 7, 0, 0):  # Ending datetime
        params['query'] = 'metaverse'
        params['tweet.fields'] = 'created_at'
        params['max_results'] = tweets_per_hour

        # Set the start and end datetime for the current hour
        start_time = current_datetime.strftime('%Y-%m-%dT%H:%M:%SZ')
        end_time = (current_datetime + timedelta(hours=1)).strftime('%Y-%m-%dT%H:%M:%SZ')
        params['start_time'] = start_time
        params['end_time'] = end_time

        response = session.get(url, params=params)
        if response.status_code != 200:
            print(f"Error: {response.status_code} - {response.text}")
            return

        json_response = response.json()
        tweets = json_response.get("data", [])

        for tweet in tweets:
            yield tweet

        # Move to the next hour
        current_datetime += timedelta(hours=1)

# Save tweet data to CSV file
def save_tweets_to_csv(tweets, filename):
    tweet_list = list(tweets)
    df = pd.DataFrame(tweet_list)
    df.to_csv(filename, index=False)

# Retrieve and save tweets
tweets_generator = retrieve_tweets()
raw_tweets_path = os.path.join("data", "raw", "tweets_hourly.csv")

save_tweets_to_csv(tweets_generator, raw_tweets_path)
