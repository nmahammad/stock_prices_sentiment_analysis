{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91948e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e3633",
   "metadata": {},
   "source": [
    "### tried methods (but failed ones) : 1.  OAuth1(client ids and client secrets) 2. API keys and secrets\n",
    "### tried best method: beare token "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee31397",
   "metadata": {},
   "source": [
    "## read csv and load in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "16e2d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@eliant_capital The new shiny object is #AI \\n...</td>\n",
       "      <td>1665886218951819264</td>\n",
       "      <td>2023-06-06T00:59:59.000Z</td>\n",
       "      <td>['1665886218951819264']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @StarryNift: üí•StarryNift Citizenship &amp;amp; ...</td>\n",
       "      <td>1665886202795544576</td>\n",
       "      <td>2023-06-06T00:59:56.000Z</td>\n",
       "      <td>['1665886202795544576']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @StarryNift: üí•StarryNift Citizenship &amp;amp; ...</td>\n",
       "      <td>1665886195279368193</td>\n",
       "      <td>2023-06-06T00:59:54.000Z</td>\n",
       "      <td>['1665886195279368193']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @StarryNift: üí•StarryNift Citizenship &amp;amp; ...</td>\n",
       "      <td>1665886181748543488</td>\n",
       "      <td>2023-06-06T00:59:51.000Z</td>\n",
       "      <td>['1665886181748543488']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AnaLok17197515: originally issued as a mem...</td>\n",
       "      <td>1665886181173624832</td>\n",
       "      <td>2023-06-06T00:59:50.000Z</td>\n",
       "      <td>['1665886181173624832']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>RT @MeStar_Game: üéâ It‚Äôs time for a MeStar Repo...</td>\n",
       "      <td>1666233456026611712</td>\n",
       "      <td>2023-06-06T23:59:47.000Z</td>\n",
       "      <td>['1666233456026611712']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>RT @Venom_ecosystem: WL Giveaway!üö®\\nRave game ...</td>\n",
       "      <td>1666233448346861569</td>\n",
       "      <td>2023-06-06T23:59:45.000Z</td>\n",
       "      <td>['1666233448346861569']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>@cb_doge And #AlphaCoin is the Best #Metaverse...</td>\n",
       "      <td>1666233439593406465</td>\n",
       "      <td>2023-06-06T23:59:43.000Z</td>\n",
       "      <td>['1666233439593406465']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>RT @sophiaverse: Welcome to SophiaVerse! ü™∑\\n\\n...</td>\n",
       "      <td>1666233428482686980</td>\n",
       "      <td>2023-06-06T23:59:41.000Z</td>\n",
       "      <td>['1666233428482686980']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>RT @Metavers_Worlds: ‚öîÔ∏è A decentralized NFT li...</td>\n",
       "      <td>1666233415405010944</td>\n",
       "      <td>2023-06-06T23:59:38.000Z</td>\n",
       "      <td>['1666233415405010944']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                   id  \\\n",
       "0    @eliant_capital The new shiny object is #AI \\n...  1665886218951819264   \n",
       "1    RT @StarryNift: üí•StarryNift Citizenship &amp; ...  1665886202795544576   \n",
       "2    RT @StarryNift: üí•StarryNift Citizenship &amp; ...  1665886195279368193   \n",
       "3    RT @StarryNift: üí•StarryNift Citizenship &amp; ...  1665886181748543488   \n",
       "4    RT @AnaLok17197515: originally issued as a mem...  1665886181173624832   \n",
       "..                                                 ...                  ...   \n",
       "175  RT @MeStar_Game: üéâ It‚Äôs time for a MeStar Repo...  1666233456026611712   \n",
       "176  RT @Venom_ecosystem: WL Giveaway!üö®\\nRave game ...  1666233448346861569   \n",
       "177  @cb_doge And #AlphaCoin is the Best #Metaverse...  1666233439593406465   \n",
       "178  RT @sophiaverse: Welcome to SophiaVerse! ü™∑\\n\\n...  1666233428482686980   \n",
       "179  RT @Metavers_Worlds: ‚öîÔ∏è A decentralized NFT li...  1666233415405010944   \n",
       "\n",
       "                   created_at   edit_history_tweet_ids  \n",
       "0    2023-06-06T00:59:59.000Z  ['1665886218951819264']  \n",
       "1    2023-06-06T00:59:56.000Z  ['1665886202795544576']  \n",
       "2    2023-06-06T00:59:54.000Z  ['1665886195279368193']  \n",
       "3    2023-06-06T00:59:51.000Z  ['1665886181748543488']  \n",
       "4    2023-06-06T00:59:50.000Z  ['1665886181173624832']  \n",
       "..                        ...                      ...  \n",
       "175  2023-06-06T23:59:47.000Z  ['1666233456026611712']  \n",
       "176  2023-06-06T23:59:45.000Z  ['1666233448346861569']  \n",
       "177  2023-06-06T23:59:43.000Z  ['1666233439593406465']  \n",
       "178  2023-06-06T23:59:41.000Z  ['1666233428482686980']  \n",
       "179  2023-06-06T23:59:38.000Z  ['1666233415405010944']  \n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "tweets_path = os.path.join(parent_dir, \"data\", \"raw\", \"tweets_hourly.csv\")\n",
    "\n",
    "df= pd.read_csv(tweets_path)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bbe0b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define the cleaning patterns using regular expressions\n",
    "whitespace = re.compile(r\"\\s+\")\n",
    "web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
    "metaverse = re.compile(r\"(?i)@metaverse(?=\\b)\")\n",
    "user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
    "\n",
    "# Apply data cleaning using regular expressions to the \"text\" column\n",
    "df[\"cleaned_text\"] = df[\"text\"].copy()  # Create a copy of the \"text\" column\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].str.replace(whitespace, \" \")\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].str.replace(web_address, \"\")\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].str.replace(user, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41ccfb",
   "metadata": {},
   "source": [
    "Sentiment analysis with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a04387d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelling each tweet with emotions label \n",
    "import flair\n",
    "sentiment_model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "804f9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "sentiments = []\n",
    "score = []\n",
    "for i in range(0, len(df)):\n",
    "    tweet = df.iloc[i, 2]  # Use the correct index of the \"text\" column\n",
    "    sentence = flair.data.Sentence(tweet)\n",
    "    sentiment_model.predict(sentence)\n",
    "    # Extract sentiment prediction\n",
    "    probs.append(sentence.labels[0].score)  # Numerical score 0-1\n",
    "    sentiments.append(sentence.labels[0].value)  # 'POSITIVE' or 'NEGATIVE'\n",
    "    if sentence.labels[0].value == \"NEGATIVE\":\n",
    "        score.append(-sentence.labels[0].score)\n",
    "    else:\n",
    "        score.append(sentence.labels[0].score)\n",
    "\n",
    "# Add probability and sentiment predictions to df\n",
    "df['probability'] = probs\n",
    "df['sentiment'] = sentiments\n",
    "df['score'] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ae227c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Convert \"created_at\" column to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# 2) Keep only \"score\" and \"created_at\" columns\n",
    "df = df[['score', 'created_at']]\n",
    "\n",
    "# Rename \"created_at\" column to \"date\"\n",
    "df = df.rename(columns={'created_at': 'date'})\n",
    "\n",
    "# 3) Convert \"date\" column to the desired format with hourly time series\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "14850297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "975ffb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average score per date\n",
    "average_scores = df.groupby('date')['score'].mean()\n",
    "\n",
    "# Create a new DataFrame with average scores per date\n",
    "df_scores = pd.DataFrame({'date': average_scores.index, 'average_score': average_scores.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5eddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
